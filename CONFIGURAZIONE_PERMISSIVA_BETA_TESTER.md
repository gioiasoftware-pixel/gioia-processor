# üîß Configurazione Permissiva per Beta Tester - Processor 2.0.0

**Scopo**: Configurare il processor 2.0.0 per accettare inventari gi√† puliti senza validazioni troppo rigide.

---

## üéØ Problema

La versione 2.0.0 ha **"maglie strette"** che potrebbero rifiutare anche inventari puliti:
- ‚ùå `SCHEMA_SCORE_TH=0.80` - Soglia troppo alta per schema_score
- ‚ùå `MIN_VALID_ROWS=0.70` - Soglia troppo alta per righe valide
- ‚ùå Validazione Pydantic rigida (name obbligatorio, vintage 1900-2099, etc.)
- ‚ùå Header confidence threshold = 0.72

**Risultato**: Inventari puliti potrebbero essere inviati a Stage 2/3 (AI) anche quando non necessario.

---

## ‚úÖ Soluzione: Configurazione Permissiva

Mantieni la **versione 2.0.0** ma configura soglie pi√π basse per inventari gi√† puliti.

### **Variabili Ambiente da Configurare**

Aggiungi queste variabili ambiente in Railway (o `.env` locale):

```env
# ============================================
# CONFIGURAZIONE PERMISSIVA PER BETA TESTER
# ============================================

# Soglie Stage 1 - PERMISSIVE (per inventari gi√† puliti)
SCHEMA_SCORE_TH=0.50          # Default: 0.80 - Abbassato per accettare pi√π file
MIN_VALID_ROWS=0.50           # Default: 0.70 - Abbassato per accettare pi√π file
HEADER_CONFIDENCE_TH=0.50     # Default: 0.72 - Abbassato per header matching

# Normalizzazione - PERMISSIVA
NORMALIZATION_POLICY=SAFE     # SAFE = pi√π permissivo, AGGRESSIVE = pi√π rigido

# Feature Flags - Disabilita AI se non necessario
IA_TARGETED_ENABLED=true      # Mantieni abilitato per casi complessi
LLM_FALLBACK_ENABLED=true     # Mantieni abilitato per casi complessi
OCR_ENABLED=true              # Mantieni abilitato per foto/PDF

# Delta per override in modalit√† SAFE
LLM_STRICT_OVERRIDE_DELTA=0.05  # Default: 0.10 - Pi√π permissivo
```

---

## üìä Confronto Soglie

| Soglia | Default (Rigido) | Permissiva (Beta Tester) | Differenza |
|--------|------------------|--------------------------|------------|
| `SCHEMA_SCORE_TH` | 0.80 | 0.50 | -37.5% |
| `MIN_VALID_ROWS` | 0.70 | 0.50 | -28.6% |
| `HEADER_CONFIDENCE_TH` | 0.72 | 0.50 | -30.6% |

**Effetto**: Con soglie pi√π basse, pi√π file puliti passeranno Stage 1 senza AI.

---

## üîÑ Comportamento con Configurazione Permissiva

### **Prima (Default Rigido)** ‚ùå

```
File pulito con schema_score=0.65, valid_rows=0.60
  ‚Üì
Stage 1: schema_score=0.65 < 0.80 ‚Üí ESCALATE
  ‚Üì
Stage 2: AI chiamata (gpt-4o-mini) - COSTO ‚Ç¨0.01-0.02
  ‚Üì
Salva
```

**Problema**: AI chiamata anche per file puliti.

---

### **Dopo (Permissiva)** ‚úÖ

```
File pulito con schema_score=0.65, valid_rows=0.60
  ‚Üì
Stage 1: schema_score=0.65 >= 0.50 ‚úÖ AND valid_rows=0.60 >= 0.50 ‚úÖ
  ‚Üì
SALVA DIRETTAMENTE - NO AI
```

**Vantaggio**: File puliti salvati senza AI, zero costi.

---

## üõ†Ô∏è Implementazione

### **Opzione 1: Variabili Ambiente (Consigliata)**

Aggiungi le variabili in Railway Dashboard:

1. Vai su **Railway Dashboard** ‚Üí Progetto Processor
2. **Settings** ‚Üí **Variables**
3. Aggiungi:
   ```
   SCHEMA_SCORE_TH=0.50
   MIN_VALID_ROWS=0.50
   HEADER_CONFIDENCE_TH=0.50
   NORMALIZATION_POLICY=SAFE
   ```
4. **Redeploy** il servizio

---

### **Opzione 2: File .env Locale**

Per test locale, crea/modifica `.env`:

```env
# Database
DATABASE_URL=postgresql://user:pass@host:port/db

# OpenAI (opzionale, ma consigliato)
OPENAI_API_KEY=your_key

# Configurazione Permissiva
SCHEMA_SCORE_TH=0.50
MIN_VALID_ROWS=0.50
HEADER_CONFIDENCE_TH=0.50
NORMALIZATION_POLICY=SAFE
```

---

## üìà Risultati Attesi

### **File Puliti (Beta Tester)**

**Prima** (soglie rigide):
- 30-40% vanno a Stage 2 (AI)
- Costo: ‚Ç¨0.01-0.02 per file
- Tempo: 20-40 secondi

**Dopo** (soglie permissive):
- 5-10% vanno a Stage 2 (solo file veramente problematici)
- Costo: ‚Ç¨0 per file puliti
- Tempo: 8-15 secondi

**Risparmio**: ~90% costi AI per file puliti

---

## ‚ö†Ô∏è Attenzione

### **Quando NON usare soglie permissive**

- ‚ùå Se ricevi inventari non puliti
- ‚ùå Se vuoi massima qualit√† dati
- ‚ùå Se vuoi che AI corregga errori automaticamente

### **Quando usare soglie permissive**

- ‚úÖ Inventari gi√† puliti/pre-processati
- ‚úÖ Beta tester con file controllati
- ‚úÖ Vuoi minimizzare costi AI
- ‚úÖ Vuoi massima velocit√†

---

## üîç Verifica Configurazione

### **Test Locale**

```bash
# Verifica che le variabili siano caricate
python -c "
from gioia-processor.core.config import get_config
config = get_config()
print(f'SCHEMA_SCORE_TH: {config.schema_score_th}')
print(f'MIN_VALID_ROWS: {config.min_valid_rows}')
print(f'HEADER_CONFIDENCE_TH: {config.header_confidence_th}')
"
```

**Output atteso**:
```
SCHEMA_SCORE_TH: 0.5
MIN_VALID_ROWS: 0.5
HEADER_CONFIDENCE_TH: 0.5
```

---

### **Test con File Pulito**

1. Carica un file pulito
2. Verifica nei log che passi Stage 1 senza escalation:
   ```
   [PIPELINE] Stage 1 parse completed: decision=save
   schema_score=0.65 valid_rows=0.60
   ```
3. Verifica che **NON** vada a Stage 2:
   ```
   [PIPELINE] Stage 2 skipped (decision=save)
   ```

---

## üìù Configurazione Graduale

Se vuoi essere pi√π conservativo, puoi abbassare gradualmente:

### **Livello 1: Moderatamente Permissivo**
```env
SCHEMA_SCORE_TH=0.65
MIN_VALID_ROWS=0.60
HEADER_CONFIDENCE_TH=0.60
```

### **Livello 2: Permissivo (Consigliato per Beta Tester)**
```env
SCHEMA_SCORE_TH=0.50
MIN_VALID_ROWS=0.50
HEADER_CONFIDENCE_TH=0.50
```

### **Livello 3: Molto Permissivo (Solo se necessario)**
```env
SCHEMA_SCORE_TH=0.40
MIN_VALID_ROWS=0.40
HEADER_CONFIDENCE_TH=0.40
```

**‚ö†Ô∏è Attenzione**: Livello 3 potrebbe accettare file con problemi.

---

## üéØ Raccomandazione Finale

**Per Beta Tester con inventari puliti**:

1. ‚úÖ **Mantieni versione 2.0.0** (non tornare alla 1.0)
2. ‚úÖ **Configura soglie permissive** (SCHEMA_SCORE_TH=0.50, MIN_VALID_ROWS=0.50)
3. ‚úÖ **Mantieni AI abilitata** (per casi complessi)
4. ‚úÖ **Monitora log** per verificare che file puliti passino Stage 1

**Vantaggi**:
- ‚úÖ Mantieni architettura modulare e manutenibile
- ‚úÖ Mantieni sistema di alerting e monitoring
- ‚úÖ Mantieni test coverage completo
- ‚úÖ Zero costi AI per file puliti
- ‚úÖ Massima velocit√† per file puliti
- ‚úÖ AI disponibile per casi complessi

---

## üìä Esempio Pratico

### **File Pulito: 100 vini, schema_score=0.65, valid_rows=0.60**

**Con Default (Rigido)**:
```
Stage 1: schema_score=0.65 < 0.80 ‚Üí ESCALATE
Stage 2: AI chiamata (gpt-4o-mini)
  ‚Üí Costo: ‚Ç¨0.01-0.02
  ‚Üí Tempo: 25-35 secondi
  ‚Üí Risultato: ‚úÖ Salvato
```

**Con Permissiva**:
```
Stage 1: schema_score=0.65 >= 0.50 ‚úÖ AND valid_rows=0.60 >= 0.50 ‚úÖ
  ‚Üí Decision: SAVE
  ‚Üí Costo: ‚Ç¨0
  ‚Üí Tempo: 10-15 secondi
  ‚Üí Risultato: ‚úÖ Salvato
```

**Risparmio**: ‚Ç¨0.01-0.02 per file, 15-20 secondi per file

---

## üîÑ Rollback

Se le soglie permissive causano problemi:

1. **Aumenta gradualmente** le soglie:
   ```env
   SCHEMA_SCORE_TH=0.60  # Da 0.50 a 0.60
   MIN_VALID_ROWS=0.55   # Da 0.50 a 0.55
   ```

2. **Monitora log** per vedere quanti file vanno a Stage 2

3. **Trova equilibrio** tra permissivit√† e qualit√†

---

**Versione Documento**: 1.0  
**Data**: 2025-01-XX  
**Autore**: AI Assistant

