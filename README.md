# ðŸ· Gioia Processor - AI Microservice v2.0.0

## ðŸ“‹ Panoramica

**Gioia Processor** Ã¨ un microservizio FastAPI per elaborazione intelligente di file inventari vini con pipeline deterministica multi-stage.

**Versione**: 2.0.0 (Refactored)  
**Architettura**: Modulare (`api/`, `core/`, `ingest/`)  
**Pipeline**: 5 stage deterministica (Gate â†’ Parse â†’ IA Mirata â†’ LLM Mode â†’ OCR)

## ðŸš€ FunzionalitÃ 

### **Pipeline Processing**
- **Stage 0 (Gate)**: Routing automatico file per tipo
- **Stage 1 (Parse Classico)**: Parsing CSV/Excel con encoding detection, normalization, validation
- **Stage 2 (IA Mirata)**: Disambiguazione header e correzione righe ambigue con `gpt-4o-mini`
- **Stage 3 (LLM Mode)**: Estrazione da testo grezzo con `gpt-4o` (solo se necessario)
- **Stage 4 (OCR)**: Estrazione testo da immagini/PDF con Tesseract + Stage 3

### **API Endpoints**
- `POST /process-inventory` - Elabora file inventario (nuova pipeline)
- `POST /process-movement` - Processa movimento inventario (consumo/rifornimento)
- `GET /status/{job_id}` - Stato elaborazione job
- `GET /health` - Health check del servizio
- `GET /api/inventory/snapshot` - Snapshot inventario con facets
- `GET /api/viewer/{view_id}` - HTML viewer inventario

### **Database**
- PostgreSQL con SQLAlchemy async
- Tabelle dinamiche per utente (`inventario_{telegram_id}`, `consumi_{telegram_id}`)
- Batch insert ottimizzato
- Job management con idempotency

## ðŸ“ Struttura Progetto

```
gioia-processor/
â”œâ”€â”€ api/                      # FastAPI application
â”‚   â”œâ”€â”€ main.py              # FastAPI app principale
â”‚   â””â”€â”€ routers/             # API routers
â”‚       â”œâ”€â”€ ingest.py        # POST /process-inventory
â”‚       â”œâ”€â”€ movements.py     # POST /process-movement
â”‚       â””â”€â”€ snapshot.py      # GET /api/inventory/snapshot, /api/viewer/*
â”‚
â”œâ”€â”€ core/                     # Moduli core
â”‚   â”œâ”€â”€ config.py            # Configurazione (pydantic-settings)
â”‚   â”œâ”€â”€ database.py          # Database interactions
â”‚   â”œâ”€â”€ job_manager.py       # Job management
â”‚   â”œâ”€â”€ logger.py            # Logging unificato (JSON)
â”‚   â””â”€â”€ alerting.py          # Sistema alerting
â”‚
â”œâ”€â”€ ingest/                   # Pipeline processing
â”‚   â”œâ”€â”€ gate.py              # Stage 0: Routing
â”‚   â”œâ”€â”€ parser.py            # Stage 1: Parse classico
â”‚   â”œâ”€â”€ llm_targeted.py      # Stage 2: IA mirata
â”‚   â”œâ”€â”€ llm_extract.py       # Stage 3: LLM mode
â”‚   â”œâ”€â”€ ocr_extract.py       # Stage 4: OCR
â”‚   â”œâ”€â”€ pipeline.py          # Orchestratore principale
â”‚   â”œâ”€â”€ validation.py        # Pydantic validation
â”‚   â”œâ”€â”€ normalization.py     # Normalization functions
â”‚   â”œâ”€â”€ csv_parser.py        # CSV parsing
â”‚   â””â”€â”€ excel_parser.py     # Excel parsing
â”‚
â”œâ”€â”€ tests/                    # Test suite (~70+ test)
â”‚   â”œâ”€â”€ test_*.py            # Test unitari e integration
â”‚   â””â”€â”€ data/                # Test fixtures
â”‚
â”œâ”€â”€ report/                   # Documentazione e verifiche
â”‚   â”œâ”€â”€ VERIFICA_COMPLETA.md
â”‚   â”œâ”€â”€ DOCUMENTAZIONE_COMPLETA.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ admin_notifications.py    # Admin notifications
â”œâ”€â”€ viewer_generator.py        # Viewer HTML generation
â”œâ”€â”€ jwt_utils.py             # JWT validation
â”œâ”€â”€ start_processor.py       # Entry point
â””â”€â”€ README.md                # Questo file
```

## ðŸ”§ Installazione e Setup

### **1. Setup Locale**
```bash
# Installa dipendenze
pip install -r requirements.txt

# Configura variabili ambiente
export DATABASE_URL="postgresql://user:pass@host:port/db"
export OPENAI_API_KEY="your_openai_key"
export PORT=8001

# Avvia server
python start_processor.py

# Oppure con uvicorn
uvicorn api.main:app --reload --port 8001
```

### **2. Test**
```bash
# Esegui tutti i test
pytest tests/

# Test con coverage
pytest tests/ --cov=ingest --cov=core --cov=api

# Test specifici
pytest tests/test_parsers.py
pytest tests/test_ingest_flow.py
```

## ðŸš€ Deploy Railway

### **1. Repository GitHub**
```bash
# Commit e push
git add .
git commit -m "Refactor processor v2.0.0"
git push origin main
```

### **2. Deploy su Railway**
1. Vai su Railway.app â†’ New Project
2. Deploy from GitHub repo
3. Seleziona repository e cartella `gioia-processor`
4. Railway rileva automaticamente Python

### **3. Variabili Ambiente**
Configura in Railway dashboard:
```env
DATABASE_URL=postgresql://user:pass@host:port/db
OPENAI_API_KEY=your_openai_api_key
PORT=8001  # Railway auto-configura
```

### **4. Verifica Deploy**
```bash
# Health check
curl https://your-app.railway.app/health

# Test processamento
curl -X POST https://your-app.railway.app/process-inventory \
  -F "telegram_id=123456" \
  -F "business_name=Test" \
  -F "file_type=csv" \
  -F "file=@test.csv"
```

## âš™ï¸ Configurazione

### **Variabili Ambiente**

**Obbligatorie**:
- `DATABASE_URL`: URL connessione PostgreSQL

**Opzionali**:
- `PORT`: Porta server (default: 8001)
- `OPENAI_API_KEY`: API key OpenAI (se mancante, AI disabilitata)

**Feature Flags**:
- `IA_TARGETED_ENABLED`: Abilita Stage 2 (default: true)
- `LLM_FALLBACK_ENABLED`: Abilita Stage 3 (default: true)
- `OCR_ENABLED`: Abilita Stage 4 (default: true)

**Vedi**: `report/ENV_VARIABLES.md` per documentazione completa

### **Endpoint API**
- `POST /process-inventory` - Elabora file inventario
- `POST /process-movement` - Processa movimento inventario
- `GET /status/{job_id}` - Stato job elaborazione
- `GET /health` - Health check
- `GET /api/inventory/snapshot` - Snapshot inventario
- `GET /api/viewer/{view_id}` - HTML viewer inventario

## ðŸ“Š Database

### **Tabelle Principali**
- `users`: Utenti Telegram (telegram_id, business_name)
- `processing_jobs`: Job elaborazione (job_id, status, processing_method)

### **Tabelle Dinamiche per Utente**
- `inventario_{telegram_id}`: Inventario vini (name, winery, vintage, qty, price, type)
- `consumi_{telegram_id}`: Log movimenti (wine_id, movement_type, quantity)

## ðŸ“ˆ Monitoring

### **Logging JSON**
Tutti i log in formato JSON strutturato con:
- `correlation_id`: ID correlazione
- `stage`: Stage pipeline
- `decision`: Decisione finale
- `metrics`: Metriche specifiche stage
- `elapsed_sec`: Tempo elaborazione

**Log leggibili in Railway dashboard**

### **Alerting**
Sistema alerting configurato per:
- Stage 3 failure rate (>= 5 fallimenti/60min)
- LLM cost (>= â‚¬0.50/60min)
- Error rate (>= 10 errori/60min)

**Vedi**: `report/VERIFICA_ALERTING.md`

## ðŸ”’ Sicurezza

- **CORS**: Configurato per comunicazione bot
- **Validazione**: Pydantic validation per tutti i dati
- **Error Handling**: Gestione errori robusta con fallback automatici
- **Idempotency**: Supporto `client_msg_id` per richieste duplicate

## ðŸ“š Documentazione

- **README.md**: Questo file (panoramica generale)
- **report/DOCUMENTAZIONE_COMPLETA.md**: Documentazione tecnica completa
- **report/VERIFICA_COMPLETA.md**: Verifica completa refactoring
- **report/ENV_VARIABLES.md**: Documentazione variabili ambiente

## ðŸš€ Roadmap

- [ ] Cache Redis per performance
- [ ] Rate limiting API
- [ ] Monitoring avanzato (Datadog, Logtail)
- [ ] Supporto piÃ¹ formati file
- [ ] OCR migliorato con AI
- [ ] Batch processing per file grandi

## ðŸ”§ Troubleshooting

### **Problemi Comuni**

#### **1. Database Connection Error**
```bash
# Verifica DATABASE_URL
echo $DATABASE_URL

# Test connessione
psql $DATABASE_URL -c "SELECT 1;"
```

#### **2. OpenAI API Error**
```bash
# Verifica OPENAI_API_KEY
echo $OPENAI_API_KEY

# Se mancante, AI features sono disabilitate (Stage 2 e 3)
```

#### **3. Port Binding Error**
Railway auto-configura `PORT`, ma per locale:
```bash
export PORT=8001
python start_processor.py
```

### **Monitoraggio**

**Logs**: Tutti i log in formato JSON su stdout (leggibili in Railway dashboard)

**Health Check**: `GET /health` endpoint per monitoraggio automatico

**Alerting**: Alert automatici per Stage 3 failure, costi LLM, errori

## ðŸ“ž Supporto

- **Documentazione**: `report/DOCUMENTAZIONE_COMPLETA.md`
- **Logs**: Railway dashboard â†’ Logs
- **Verifiche**: `report/VERIFICA_COMPLETA.md`

---

**Versione**: 2.0.0  
**Data**: 2025-01-XX
